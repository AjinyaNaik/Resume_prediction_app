{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a2c5a4-d1df-49d6-a3ed-b5d155d0f1d6",
   "metadata": {},
   "source": [
    "## Resume Screening application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529a4ad4-b9b0-4a26-9409-f48ef349aed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ajink\\anaconda3\\envs\\pandas_playground\\lib\\site-packages (1.26.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/60.8 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 816.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\ajink\\anaconda3\\envs\\pandas_playground\\lib\\site-packages (2.1.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ajink\\anaconda3\\envs\\pandas_playground\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ajink\\anaconda3\\envs\\pandas_playground\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ajink\\anaconda3\\envs\\pandas_playground\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ajink\\anaconda3\\envs\\pandas_playground\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading numpy-2.2.2-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.9 MB 5.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.8/12.9 MB 8.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 9.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.0/12.9 MB 10.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.9 MB 11.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.2/12.9 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.8/12.9 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.4/12.9 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.9/12.9 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.5/12.9 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.1/12.9 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.6/12.9 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.2/12.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.8/12.9 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.9 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.1/12.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.6/12.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.9 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.9 MB 12.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.4/12.9 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.9/12.9 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.5/12.9 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.9/12.9 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.6 MB 16.8 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.1/11.6 MB 13.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.6/11.6 MB 13.0 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.2/11.6 MB 13.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.9/11.6 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.0/11.6 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.6/11.6 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.1/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.7/11.6 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.3/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.9/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.5/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.6/11.6 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.8/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 12.3 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.1\n",
      "    Uninstalling pandas-2.1.1:\n",
      "      Successfully uninstalled pandas-2.1.1\n",
      "Successfully installed numpy-2.2.2 pandas-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5be4c7-0e77-4e13-a194-53da821bddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ajink\\anaconda3\\envs\\pandas_playground\\lib\\site-packages (from scikit-learn) (2.2.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     -------------------- ------------------- 30.7/60.8 kB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/11.1 MB 6.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/11.1 MB 8.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/11.1 MB 10.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.0/11.1 MB 10.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.7/11.1 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.2/11.1 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.6/11.1 MB 11.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.1/11.1 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.6/11.1 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.3/11.1 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.1 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.4/11.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.0/11.1 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.5/11.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.1 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.3/11.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.8/11.1 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 11.9 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.1-cp311-cp311-win_amd64.whl (43.9 MB)\n",
      "   ---------------------------------------- 0.0/43.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/43.9 MB 11.6 MB/s eta 0:00:04\n",
      "    --------------------------------------- 1.1/43.9 MB 13.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.5/43.9 MB 11.6 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.5/43.9 MB 11.6 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.9/43.9 MB 8.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.5/43.9 MB 9.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.9/43.9 MB 9.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.5/43.9 MB 9.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.0/43.9 MB 9.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.7/43.9 MB 10.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.2/43.9 MB 10.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.8/43.9 MB 10.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 6.3/43.9 MB 10.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 6.9/43.9 MB 10.8 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.6/43.9 MB 11.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.2/43.9 MB 11.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.8/43.9 MB 11.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.3/43.9 MB 11.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.8/43.9 MB 11.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.3/43.9 MB 11.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 10.9/43.9 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 11.5/43.9 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 12.0/43.9 MB 11.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 12.7/43.9 MB 12.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 13.3/43.9 MB 12.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 13.8/43.9 MB 12.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 14.5/43.9 MB 12.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.0/43.9 MB 12.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 15.6/43.9 MB 12.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.3/43.9 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 16.7/43.9 MB 12.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.3/43.9 MB 12.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 17.9/43.9 MB 12.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.4/43.9 MB 12.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.0/43.9 MB 12.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.6/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.1/43.9 MB 12.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.7/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 21.2/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 21.8/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 22.2/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 22.9/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.5/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.1/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 24.6/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.2/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 25.9/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 26.4/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 27.0/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 27.5/43.9 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.1/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 28.7/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.2/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 29.8/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 30.4/43.9 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.0/43.9 MB 12.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.4/43.9 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.8/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.4/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.9/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 33.5/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 34.1/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 34.7/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.2/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.8/43.9 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.3/43.9 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.0/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.6/43.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.1/43.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 38.6/43.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.1/43.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.7/43.9 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.2/43.9 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.8/43.9 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.3/43.9 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.0/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.4/43.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.1/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.7/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/43.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.9/43.9 MB 11.1 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d419a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.0 kB 320.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 806.3 kB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/15.8 MB 5.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.7/15.8 MB 8.7 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.3/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.0/15.8 MB 11.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.5/15.8 MB 11.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.0/15.8 MB 11.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.7/15.8 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.4/15.8 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 6.0/15.8 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.2/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.9/15.8 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.4/15.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.1/15.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.6/15.8 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.3/15.8 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.8/15.8 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.2/15.8 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.5/15.8 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.3/15.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ajink\\anaconda3\\envs\\pandas_playground\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ajink\\anaconda3\\envs\\pandas_playground\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d254356-48a0-40c0-ab93-a5d32efead53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "266dfa03-667e-4b8c-b1bf-4988be0d0fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Computer Skills: â¢ Proficient in MS office (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Testing</td>\n",
       "      <td>â Willingness to accept the challenges. â ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Testing</td>\n",
       "      <td>PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Testing</td>\n",
       "      <td>COMPUTER SKILLS &amp; SOFTWARE KNOWLEDGE MS-Power ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Testing</td>\n",
       "      <td>Skill Set OS Windows XP/7/8/8.1/10 Database MY...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Category                                             Resume\n",
       "0    Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1    Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2    Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3    Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4    Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
       "..            ...                                                ...\n",
       "957       Testing  Computer Skills: â¢ Proficient in MS office (...\n",
       "958       Testing  â Willingness to accept the challenges. â ...\n",
       "959       Testing  PERSONAL SKILLS â¢ Quick learner, â¢ Eagerne...\n",
       "960       Testing  COMPUTER SKILLS & SOFTWARE KNOWLEDGE MS-Power ...\n",
       "961       Testing  Skill Set OS Windows XP/7/8/8.1/10 Database MY...\n",
       "\n",
       "[962 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"UpdatedResumeDataSet.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cabd0b-99e3-4877-9928-924116aaed72",
   "metadata": {},
   "source": [
    "## Exploring Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e388e293-0dbd-40d6-aee0-852c69d56405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Java Developer               84\n",
       "Testing                      70\n",
       "DevOps Engineer              55\n",
       "Python Developer             48\n",
       "Web Designing                45\n",
       "HR                           44\n",
       "Hadoop                       42\n",
       "Blockchain                   40\n",
       "ETL Developer                40\n",
       "Operations Manager           40\n",
       "Data Science                 40\n",
       "Sales                        40\n",
       "Mechanical Engineer          40\n",
       "Arts                         36\n",
       "Database                     33\n",
       "Electrical Engineering       30\n",
       "Health and fitness           30\n",
       "PMO                          30\n",
       "Business Analyst             28\n",
       "DotNet Developer             28\n",
       "Automation Testing           26\n",
       "Network Security Engineer    25\n",
       "SAP Developer                24\n",
       "Civil Engineer               24\n",
       "Advocate                     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5332f91c-6f25-4955-9f19-ca65884ae1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Science', 'HR', 'Advocate', 'Arts', 'Web Designing',\n",
       "       'Mechanical Engineer', 'Sales', 'Health and fitness',\n",
       "       'Civil Engineer', 'Java Developer', 'Business Analyst',\n",
       "       'SAP Developer', 'Automation Testing', 'Electrical Engineering',\n",
       "       'Operations Manager', 'Python Developer', 'DevOps Engineer',\n",
       "       'Network Security Engineer', 'PMO', 'Database', 'Hadoop',\n",
       "       'ETL Developer', 'DotNet Developer', 'Blockchain', 'Testing'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb873ae-2710-4f79-af3f-940d4d8b0955",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aad41aa-0f61-413c-87ee-6c507b47bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(txt):\n",
    "    cleanText= re.sub(\"http\\S+\\s\",\" \",txt)\n",
    "    cleanText= re.sub(\"RT|CC\",\" \",cleanText)\n",
    "    cleanText= re.sub(\"#\\S+\\s\",\" \",cleanText)\n",
    "    cleanText= re.sub(\"@\\S+\",\" \",cleanText)\n",
    "    cleanText= re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"),\" \",cleanText)\n",
    "    cleanText= re.sub(\"r'[^\\x00-\\x7f]\",\" \",cleanText)\n",
    "    cleanText= re.sub(r\"\\s+\",\" \",cleanText)\n",
    "    cleanText = re.sub(r\"^[\\-\\•\\*\\d+.\\)]\\s*\", \" \", cleanText, flags=re.M)\n",
    "    return cleanText\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d98cb8-8ca2-4b1b-9d06-9578d232ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Resume']= data['Resume'].apply(lambda x: cleanText(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83b2e0-7ce7-4504-ab60-d22eef1d8e00",
   "metadata": {},
   "source": [
    "### Example resume after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a69129-cdaa-4e00-92d8-e14ee321d0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skills Programming Languages Python pandas numpy scipy scikit learn matplotlib Sql Java JavaScript JQuery Machine learning Regression SVM NaÃ¯ve Bayes KNN Random Forest Decision Trees Boosting techniques Cluster Analysis Word Embedding Sentiment Analysis Natural Language processing Dimensionality reduction Topic Modelling LDA NMF PCA Neural Nets Database Visualizations Mysql SqlServer Cassandra Hbase ElasticSearch D3 js DC js Plotly kibana matplotlib ggplot Tableau Others Regular Expression HTML CSS Angular 6 Logstash Kafka Python Flask Git Docker computer vision Open CV and understanding of Deep learning Education Details Data Science Assurance Associate Data Science Assurance Associate Ernst Young LLP Skill Details JAVASCRIPT Exprience 24 months jQuery Exprience 24 months Python Exprience 24 monthsCompany Details company Ernst Young LLP description Fraud Investigations and Dispute Services Assurance TECHNOLOGY ASSISTED REVIEW TAR Technology Assisted Review assists in accelerating the review process and run analytics and generate reports Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain this tool implements predictive coding and topic modelling by automating reviews resulting in reduced labor costs and time spent during the lawyers review Understand the end to end flow of the solution doing research and development for classification models predictive analysis and mining of the information present in text data Worked on analyzing the outputs and precision monitoring for the entire tool TAR assists in predictive coding topic modelling from the evidence by following EY standards Developed the classifier models in order to identify red flags and fraud related issues Tools Technologies Python scikit learn tfidf word2vec doc2vec cosine similarity NaÃ¯ve Bayes LDA NMF for topic modelling Vader and text blob for sentiment analysis Matplot lib Tableau dashboard for reporting MULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS USA CLIENTS TEXT ANALYTICS MOTOR VEHICLE CUSTOMER REVIEW DATA Received customer feedback survey data for past one year Performed sentiment Positive Negative Neutral and time series analysis on customer comments across all 4 categories Created heat map of terms by survey category based on frequency of words Extracted Positive and Negative words across all the Survey categories and plotted Word cloud Created customized tableau dashboards for effective reporting and visualizations CHATBOT Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation reservation options and so on This chat bot serves entire product related questions Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant recommended questions Tools Technologies Python Natural language processing NLTK spacy topic modelling Sentiment analysis Word Embedding scikit learn JavaScript JQuery SqlServer INFORMATION GOVERNANCE Organizations to make informed decisions about all of the information they store The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk Scan data from multiple sources of formats and parse different file formats extract Meta data information push results for indexing elastic search and created customized interactive dashboards using kibana Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant Outdated or Trivial Preforming full text search analysis on elastic search with predefined methods which can tag as PII personally identifiable information social security numbers addresses names etc which frequently targeted during cyber attacks Tools Technologies Python Flask Elastic Search Kibana FRAUD ANALYTIC PLATFORM Fraud Analytics and investigative platform to review all red flag cases â\\x80¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics Tools Technologies HTML JavaScript SqlServer JQuery CSS Bootstrap Node js D3 js DC js'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Resume'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06478094-20fe-40d9-95d8-154b9f3b48db",
   "metadata": {},
   "source": [
    "## Words into Categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b2e54-9c4e-4921-a4f0-b42c73a3ae2b",
   "metadata": {},
   "source": [
    "### Using scikit learn library to solve this supervised -learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "452d223c-0dc8-443c-8c43-04b16fa0f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le= LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec83117-b7c5-4a1f-83bc-279775582766",
   "metadata": {},
   "source": [
    "### Encoding Labeles from string into numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb4bac2-5bd8-4523-ab65-148613a34886",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit(data['Category'])\n",
    "data['Category']= le.transform(data[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9935a20-1c61-4906-88bc-4c905d18299c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 12,  0,  1, 24, 16, 22, 14,  5, 15,  4, 21,  2, 11, 18, 20,  8,\n",
       "       17, 19,  7, 13, 10,  9,  3, 23])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70c7ed83-8810-40a2-9ee7-341a1f2b4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Data Science', 'HR', 'Advocate', 'Arts', 'Web Designing',\n",
    " #      'Mechanical Engineer', 'Sales', 'Health and fitness',\n",
    "  #     'Civil Engineer', 'Java Developer', 'Business Analyst',\n",
    "   #    'SAP Developer', 'Automation Testing', 'Electrical Engineering',\n",
    "    #   'Operations Manager', 'Python Developer', 'DevOps Engineer',\n",
    "    #   'Network Security Engineer', 'PMO', 'Database', 'Hadoop',\n",
    "    #   'ETL Developer', 'DotNet Developer', 'Blockchain', 'Testing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee7c55-be84-4876-8bc6-6d6c3f884f32",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612bc2e-3533-4bd8-bbf1-161266b3173c",
   "metadata": {},
   "source": [
    "### Generete TFIDF score for Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26fd6c89-3e02-4181-9a5d-a72ffc3f90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(data['Resume'])\n",
    "## Save the scores for each word in requiredText\n",
    "requiredText= tfidf.transform(data['Resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a6dfdd-7c54-44ae-bd33-e5f3b3aa7fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 7370)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requiredText.shape ## Scores for each resume "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577d5b3-f5ee-4d72-88e5-d319e3ece2d1",
   "metadata": {},
   "source": [
    "## Split the Dataset into Train and test in order to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34532968-dc5b-4616-bf0f-169593632a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af9944-1090-44fc-b0ff-8fa322b83779",
   "metadata": {},
   "source": [
    "### train_test_split\n",
    "#### Split arrays or matrices into random train and test subsets.\n",
    "    Parameters:\n",
    "*arrays\n",
    "sequence of indexables with same length / shape[0]\n",
    "Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes### .\n",
    "\n",
    "test_size\n",
    "float or int, default=None\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to ### 0.25.\n",
    "\n",
    "train_size\n",
    "float or int, default=None\n",
    "If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the t### est size.\n",
    "\n",
    "random_state\n",
    "int, RandomState instance or None, default=None\n",
    "Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls. ### See Glossary.\n",
    "\n",
    "shuffle\n",
    "bool, default=True\n",
    "Whether or not to shuffle the data before splitting. If shuffle=False then strat### ify must be None.\n",
    "\n",
    "stratify\n",
    "ar\n",
    "If not None, data is split in a stratified fashion, using this as the class labels.\n",
    "#### Returns:\n",
    "splittinglist, length=2 * len(arrays)ray-like, default=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67143df1-2477-4deb-a6f9-a8970fc30e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(requiredText, data['Category'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d56a3477-1d0e-4446-9893-8c3f11d42867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(769, 7370)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20788f44-c60c-4de0-b62c-ff02640461ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 7370)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e0200-6bc4-480f-bfa7-47f341dfb8a8",
   "metadata": {},
   "source": [
    "## Now train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee4729fc-1c65-4684-b369-c2539fb7915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 15 15 13 14 17 16  2  0 14 13 12 16 23 20  5  6  4 10  9 19  1 10 23\n",
      " 23 21 22 22  2 12 18  1  8 24 11 23  7 12 24  8 18  6  8 19 24 23 21  1\n",
      " 15  4 15 22 11  5 15 13  1 19  5 12 22 22 20 24 21 18 12 10 10 20 10  8\n",
      "  9 21 17 21  0 17 16 14 15 11 11  8 20  3 19  8  0  2  9 10  2 23 20 20\n",
      " 23 12 18 12  7 16  8 14 18  3 14 19 14 14 15 18  8  2 21 18 23 10 23  5\n",
      " 11 15 12  3  5  3  7 12 19  8 20 19  3 15  9 19  1 23 21  5 20 15 16  7\n",
      "  7  8 15 18  1 15 13 20  7  4 18 11  5 15  5 12  9 22 18 21  8 23  4 12\n",
      " 24 16 15 22  8 22  3 16 23 23 12  7 16 18  5  3 18  8 23 23 20 21  6  7\n",
      " 23]\n",
      "98.44559585492227 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf=OneVsRestClassifier(KNeighborsClassifier())\n",
    "clf.fit(X_train,y_train)\n",
    "prediction_on_test=clf.predict(X_test)\n",
    "print(prediction_on_test)\n",
    "\n",
    "## Now lets print the accuracy of our model on our test dataset\n",
    "print(accuracy_score(y_test,prediction_on_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6cc68-6d98-4c30-94b3-0a6f0bd29186",
   "metadata": {},
   "source": [
    "#### Our model is 98.45% accurate in its predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac5d1c-6e3a-42a2-9864-288b2a9a1109",
   "metadata": {},
   "source": [
    "## Prediction System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fbf329b-0f61-4142-9f1b-a14d4c13c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resume=\"\"\"Profile\n",
    "I am a Computer Science undergraduate at Purdue University with strong programming skills in Java and Python. Experienced in working with MySQL databases and front-end technologies like HTML, CSS, and JavaScript. Actively exploring Cloud computing and Machine Learning. Proficient in Python, REST API development, Spring Boot applications, and react for web development, with firsthand experience in data analysis.\n",
    "Education\n",
    "Purdue University Aug 2022- May 2026\n",
    "Bachelor of Science, Computer Science\n",
    "GPA: 3.95/4.0\n",
    "Proud Member of UPE (Upsilon Pi Epsilon)\n",
    "Relevant Courses: Data Structures and algorithm(honors), Computer Architecture, Intro to C, Computer Networks, Software Engineering\n",
    "Skills\n",
    "•\n",
    "Java\n",
    "•\n",
    "Data Structures\n",
    "•\n",
    "MySQL\n",
    "•\n",
    "Git and GitHub\n",
    "•\n",
    "Node.js\n",
    "•\n",
    "Python Pandas\n",
    "•\n",
    "JavaScript\n",
    "•\n",
    "Data Analytics\n",
    "•\n",
    "Agile Methodologies\n",
    "•\n",
    "C language\n",
    "•\n",
    "React.js\n",
    "•\n",
    "Spring Boot.\n",
    "•\n",
    "Computer Security\n",
    "Experience\n",
    "Undergraduate Research Assistant – Purdue University July 2024- Present\n",
    "•\n",
    "Contributing to a research project examining how data visualization techniques influence decision-making processes across various fields.\n",
    "•\n",
    "Collaborate closely with faculty, analyzing diverse datasets to identify effective visualization methods for non-expert audiences.\n",
    "•\n",
    "Evaluate and compare distinct graphs, developing guidelines to optimize clarity, accuracy, and impact in data presentations.\n",
    "CS Student Scholar Mentor -Purdue University Jan 2024- Present\n",
    "•\n",
    "Guiding students in introductory Computer Science courses and Data Structures.\n",
    "•\n",
    "Offering support and expertise in Math calculus to enhance mathematical understanding.\n",
    "•\n",
    "Providing general academic support, including study strategies and time management.\n",
    "Undergraduate Teaching Assistant- Purdue University May 2024- Present\n",
    "•\n",
    "Assist in managing administrative tasks and supporting students in the year-long Senior Capstone course.\n",
    "•\n",
    "Collaborate in designing a structured syllabus and creating Python-based assignments for the Intro to Data Analytics course.\n",
    "•\n",
    "Support student learning by providing guidance and mentorship, helping them develop essential data analysis skills.\n",
    "National Cyber League Spring 2024 – Purdue University April 2024\n",
    "•\n",
    "Ranked 229th out of 4,199 teams, placing in the top 95th percentile nationally with a score of 1805/3000 points.\n",
    "•\n",
    "Demonstrated technical proficiency in Cryptography, Forensics, Network Traffic Analysis, and Open-Source Intelligence during the competition.\n",
    "•\n",
    "Displayed strong teamwork and critical thinking skills in addressing complex cybersecurity challenges.\n",
    "Projects\n",
    "SMC Gear Checkout and Studio Booking System Enhancement\n",
    "•\n",
    "Enhanced Online Booking Portal: Redesigned the Purdue Sweetwater Music Center’s online portal, implementing a gear checkout system with tier-based access control and real-time tracking, integrated with studio bookings for seamless scheduling.\n",
    "•\n",
    "Tech Stack Implementation: Developed the solution using React.js, Node.js, Airtable, Git for version control, and deployed it on Vercel to ensure efficient and reliable performance.\n",
    "Web Page Indexing and Query Program\n",
    "•\n",
    "Developed a web crawler in C language to index multiple web pages, storing word counts in trie data structures for efficient management.\n",
    "•\n",
    "Enable user queries to search and match web pages based on gathered statistics, implementing advanced search functionality.\n",
    "•\n",
    "Optimized data structures for accurate word count storage and fast query retrieval, enhancing program performance.\n",
    "Budget Application\n",
    "•\n",
    "A personal expense management tool designed to streamline financial tracking and analysis using Python.\n",
    "•\n",
    "Utilized Pandas for efficient data manipulation, allowing users to analyze spending patterns and track expenses effortlessly.\n",
    "•\n",
    "Integrated Matplotlib to create dynamic, visually appealing charts and graphs that provide clear insights into users' financial health.\n",
    "•\n",
    "Designed an intuitive, user-friendly interface for seamless expense entry, categorization, and trend analysis, enhancing user engagement and financial awareness.\n",
    "Certifications\n",
    "•\n",
    "Udemy: Java Networking Issued September 2024\n",
    "•\n",
    "Udemy: Data Analysis with Python and Pandas- Certificate Issued March 2024\n",
    "•\n",
    "Udemy: Understanding HTML and CSS-Certificate Issued October 2023.\n",
    "•\n",
    "Udemy: Core Python for Everyone- Certificate Issued September 2023.\n",
    "Other Achievements\n",
    "•\n",
    "Dean's & Semester Honor's List- Purdue University December 2022-May 2024.\n",
    "•\n",
    "Ripple Award March 2024\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a1711f7-9cba-4e94-a6e0-06867b9154a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf, open('tfidf.pkl','wb'))\n",
    "pickle.dump(clf, open('clf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc149d7-ca47-4a32-8928-fd678aaace9b",
   "metadata": {},
   "source": [
    "## Main Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cf2d20cd-7f3c-4743-bf34-66941ea0c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category:  Data Science\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the trained classifier\n",
    "clf=pickle.load(open('clf.pkl','rb'))\n",
    "\n",
    "# Load the TFID vectorizer\n",
    "tfidf= pickle.load(open('tfidf.pkl','rb'))\n",
    "\n",
    "# clean the resume\n",
    "cleaned_resume= cleanText(my_resume)\n",
    "#print(cleaned_resume)\n",
    "\n",
    "# Transform\n",
    "input_features=tfidf.transform([cleaned_resume])\n",
    "\n",
    "# Make prediction\n",
    "prediction_id=clf.predict(input_features)[0]\n",
    "\n",
    "# Mapping to category name\n",
    "category_mapping={\n",
    "    6:\"Data Science\",\n",
    "    12:\"HR\",\n",
    "    0:\"Advocate\",\n",
    "    1:\"Arts\",\n",
    "    24:\"Web Designing\",\n",
    "    16:\"Mechanical Engineer\",\n",
    "    22:\"Sales\",\n",
    "    14:\"Health and fitness\",\n",
    "    5:\"Civil Engineer\",\n",
    "    15:\"Java Developer\",\n",
    "    4:\"Business Analyst\",\n",
    "    21:\"SAP Developer\",\n",
    "    2:\"Automation Testing\",\n",
    "    11:\"Electrical Engineering\",\n",
    "    18:\"Operations Manager\",\n",
    "    20:\"Python Developer\",\n",
    "    8:\"DevOps Engineer\",\n",
    "    17:\"Network Security Engineer\",\n",
    "    19:\"PMO\",\n",
    "    7:\"Database\",\n",
    "    13:\"Hadoop\",\n",
    "    10:\"ETL Developer\",\n",
    "    9:\"DotNet Developer\",\n",
    "    3:\"Blockchain\",\n",
    "    23:\"Testing\" \n",
    "}\n",
    "category_name= category_mapping.get(prediction_id,\"Unkown\")\n",
    "print(\"Predicted Category: \",category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575567f-9b65-42f5-b6f3-f566c626585c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
